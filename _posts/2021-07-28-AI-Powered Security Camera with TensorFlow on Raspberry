---
title: "Edge AI-Powered Security Camera with TensorFlow on Raspberry"
header:
  overlay_color: "#000"
  overlay_filter: "0.4"
  overlay_image: "assets/images/security_cam/nodered1.png"
  teaser: "assets/images/security_cam/nodered1.png"
  og_image: "assets/images/security_cam/nodered1.png"
actions:
  - label: "Blog"
    url: "/year-archive/"
categories:
  - Computer
tags:
  - IoT
  - Embedded
toc: true
--- 
# ğŸ” Building an Edge AI-Powered Security Camera with Raspberry Pi 3B+

*By Chandula Nethmal â€“ July 2025*

Security systems are becoming increasingly intelligent, decentralized, and affordable. With advancements in Edge AI and embedded systems, it's now possible to run real-time person detection and motion analysis on low-cost hardware like the **Raspberry Pi 3B+**.

In this blog, Iâ€™ll walk you through how I built a **web-based, intelligent security camera system** using Raspberry Pi 3B+ and a camera moduleâ€”equipped with live video streaming, AI-powered person detection, motion alerts, and an interactive configuration interface.

---

## ğŸ¯ Project Objective

The goal of this project was to create a **self-contained, edge-based security solution** that:

- Operates in real time without relying on cloud resources
- Detects motion and people using lightweight AI models
- Streams video and displays detections through a responsive web interface
- Allows user control over detection behavior from a browser UI
- Runs efficiently on Raspberry Pi 3 Model B+ hardware

This system is suitable for home automation, lab monitoring, IoT surveillance, and education in computer vision or embedded systems.

---

## ğŸ› ï¸ Hardware and Software Stack

| Category        | Component                              |
|-----------------|-----------------------------------------|
| ğŸ§  Platform      | Raspberry Pi 3 Model B+                  |
| ğŸ“· Camera        | Raspberry Pi Camera Module or USB cam   |
| ğŸ“š Libraries     | OpenCV, Flask, TensorFlow Lite          |
| ğŸŒ Frontend      | HTML, CSS, JavaScript (Vanilla)         |
| ğŸ’¡ AI Model      | MobileNet SSD (pre-trained TFLite model)|
| ğŸ–¥ï¸ UI Framework  | Flask + AJAX + Bootstrap-inspired layout|
| ğŸ§ª Detection     | Frame differencing + object detection (person) |

---

## ğŸ§  Key Functionalities

### âœ… 1. Live Video Streaming  
A lightweight Flask backend serves a real-time MJPEG stream from the camera. The stream can be toggled on/off from the UI.

### âœ… 2. Motion Detection  
Implemented using OpenCVâ€™s grayscale frame differencing with thresholding. When sufficient pixel change is detected between frames, motion is triggered.

### âœ… 3. Person Detection with Edge AI  
Using a MobileNet SSD model converted to TensorFlow Lite format, person detection is triggered either manually or automatically via motion events. The detection pipeline processes frames efficiently to identify persons in real-time.

### âœ… 4. Advanced Detection Mode  
This hybrid mode enables AI-based person detection **only when motion is detected**, and remains active for a short configurable window (e.g., 10 seconds) to optimize CPU usage.

### âœ… 5. Smart Web Interface  
The browser-based UI displays:
- Real-time stream
- Motion status
- Current timestamp
- Buttons to capture snapshots, toggle recording, and switch modes
- A separate **Configurations tab** for enabling/disabling features

### âœ… 6. Recording and Snapshots  
Users can capture images or toggle video recording, which is saved directly to the Raspberry Pi storage.

---

## ğŸ’» Web UI Overview

### ğŸ“º Live View Tab:
- Real-time video feed
- Timestamp
- Motion alert indicator
- Controls: ğŸ“¸ Capture, ğŸ¥ Toggle Stream, ğŸ”´ Start/Stop Recording

### âš™ï¸ Configurations Tab:
- ğŸ‘¤ Toggle Person Detection
- ğŸŒ€ Toggle Motion Detection
- ğŸ¤– Enable Advanced Mode (person detection only when motion is active)
- ğŸ¨ Switch between Light, Dark, and Cyberpunk themes

### ğŸ¨ Theme Support:
Built-in UI themes allow users to switch visual styles instantly without reloading the page.

---

## ğŸ§ª Performance on Raspberry Pi 3B+

Despite being an older board with only 1 GB RAM, the Raspberry Pi 3B+ performs adequately with optimized frame sizes and efficient models:

- Live stream operates at ~10-15 FPS
- Motion detection uses minimal CPU
- AI person detection is triggered only as needed
- TFLite keeps memory usage low and inference fast

âš ï¸ Tip: Use 320Ã—240 or 480Ã—360 resolution for better performance on Raspberry Pi 3B+.

---

## ğŸ“‚ Code Structure
EdgeAiSecureCam/
â”œâ”€â”€ camera_stream.py # Flask app and video feed
â”œâ”€â”€ camera_object_det.py # AI object detection
â”œâ”€â”€ templates/index.html # Web UI
â”œâ”€â”€ static/ # Optional CSS/JS
â”œâ”€â”€ tflite_model.tflite # AI model file
â””â”€â”€ requirements.txt # Dependencies


---

## ğŸš€ Possible Future Enhancements

- ğŸ“© Telegram/Email alerts on person detection
- ğŸ§  Upgrade to YOLOv5 Nano or EfficientDet-Lite models
- ğŸ“¦ Save detection logs and build a history timeline
- ğŸ”” Add sound alerts on detection
- â˜ï¸ Sync recorded videos to a cloud drive

---

## ğŸ“¸ Gallery

> *(Insert real screenshots, detection examples, and Raspberry Pi setup photos here)*

---

## ğŸ§‘â€ğŸ’» Source Code

> GitHub: [github.com/yourusername/EdgeAiSecureCam](#)

Feel free to fork, contribute, or use it for your personal smart security solutions.

---

## ğŸ§  Lessons Learned

This project was a great way to explore:

- Deploying AI at the edge
- Optimizing real-time applications on constrained hardware
- Integrating OpenCV and Flask
- Designing user-friendly, browser-based control panels

By offloading intelligence to the device itself, this project demonstrates how **Edge AI can make security systems faster, smarter, and more private.**

---

## ğŸ Conclusion

Weâ€™ve turned a $35 board into a **smart, responsive, and intelligent security camera system**. This is just the beginning of whatâ€™s possible with Edge AI and embedded systems. Whether you're an enthusiast, student, or engineerâ€”this project is an excellent starting point for building modern, autonomous IoT devices.

---

ğŸ’¬ **Have questions or feedback?** Iâ€™d love to hear your thoughts in the comments below or via GitHub.
